{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43901d03f99741f",
   "metadata": {},
   "source": [
    "# The Inverted Pendulum (or the Cart-Pole System)\n",
    "\n",
    "In this notebook, we will go through implementing the inverted pendulum system for which we'll train a neural network to learn to control the pendulum state.\n",
    "\n",
    "We will train a separate network to learn the system dynamics as well. \n",
    "\n",
    "A part of this exercise will also show you how to make animations in matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:42:28.864491Z",
     "start_time": "2024-07-03T13:42:26.538298Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import neuralode\n",
    "import copy\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter('ignore', RuntimeWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b673b74ad153fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:42:31.753592Z",
     "start_time": "2024-07-03T13:42:31.747981Z"
    }
   },
   "outputs": [],
   "source": [
    "# For convenience, we define the default tensor device and dtype here\n",
    "torch.set_default_device('cpu')\n",
    "# In neural networks, we prefer 32-bit/16-bit floats, but for precise integration, 64-bit is preferred. We will revisit this later when we need to mix integration with neural network training\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784015b65db64dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:42:32.037060Z",
     "start_time": "2024-07-03T13:42:32.028718Z"
    }
   },
   "outputs": [],
   "source": [
    "mass_cart   = torch.tensor(2.0)  # kg\n",
    "mass_pole   = torch.tensor(0.1)  # kg\n",
    "length_pole = torch.tensor(1.0)  # m\n",
    "gravity     = torch.tensor(9.81) # m/s^2\n",
    "friction_cart = torch.tensor(0.0)\n",
    "friction_pole = torch.tensor(0.0)\n",
    "\n",
    "def inverted_pendulum(state, time, force, mc, mp, l, g, mu_c, mu_p):\n",
    "    theta, theta_dot, x, x_dot = state[...,0], state[...,1], state[...,2], state[...,3]\n",
    "    \n",
    "    dtheta = theta_dot\n",
    "    dx = x_dot\n",
    "    \n",
    "    stheta, ctheta = theta.sin(), theta.cos()\n",
    "    \n",
    "    theta_dot_sq = theta_dot.square()\n",
    "    total_mass = mc + mp*stheta.square()\n",
    "    \n",
    "    if torch.all(mu_c == 0.0) and torch.all(mu_p == 0.0):\n",
    "        pole_moment_of_inertia = mp * l/2\n",
    "        counter_force = (force + pole_moment_of_inertia * stheta * theta_dot_sq)\n",
    "        dtheta_dot = stheta * g - ctheta * counter_force / total_mass\n",
    "        dtheta_dot = dtheta_dot * 2/l / (4.0/3.0 - mp * ctheta.square() / total_mass)\n",
    "        dx_dot = (counter_force - pole_moment_of_inertia * ctheta * dtheta_dot)\n",
    "        dx_dot = dx_dot / total_mass\n",
    "    else:\n",
    "        sgn_xdot = torch.sign(x_dot)\n",
    "        paren1_pre = -force - mp * l/2 * theta_dot_sq * (stheta + mu_c * ctheta * sgn_xdot) + mu_c * g * sgn_xdot\n",
    "        \n",
    "        dtheta_dot_common = g * stheta - (mu_p / mp) * x_dot * 2/l\n",
    "        dtheta_dot = dtheta_dot_common + ctheta * paren1_pre \n",
    "        dtheta_dot = dtheta_dot * 2/l / (4.0/3.0 - mp * ctheta / total_mass * (ctheta - mu_c * sgn_xdot))\n",
    "        \n",
    "        Nc = total_mass * g - mp * l/2 * (dtheta_dot * stheta + theta_dot_sq * ctheta)\n",
    "        \n",
    "        corr_needed = (torch.sign(Nc) < 0) & (mu_c > 0.0)\n",
    "        sgn_Ncxdot = torch.sign(Nc*x_dot)\n",
    "        paren1_post = -force - mp * l/2 * theta_dot_sq * (stheta + mu_c * ctheta * sgn_Ncxdot) + mu_c * g * sgn_Ncxdot\n",
    "            \n",
    "        dtheta_dot_pre = dtheta_dot_common + ctheta * paren1_post\n",
    "        dtheta_dot = torch.where(corr_needed, dtheta_dot_pre * 2/l / (4.0/3.0 - mp*ctheta/total_mass * (ctheta - mu_c * sgn_Ncxdot)), dtheta_dot)\n",
    "    \n",
    "        Nc = torch.where(corr_needed, (mc + mp) * g - mp * l/2 * (dtheta_dot * stheta + theta_dot_sq * ctheta), Nc)\n",
    "            \n",
    "        dx_dot = (force + mp * (theta_dot_sq * stheta - dtheta_dot * ctheta) - mu_c * Nc * torch.sign(Nc * x_dot))/(mc + mp)\n",
    "    \n",
    "    return torch.stack([\n",
    "        dtheta,\n",
    "        dtheta_dot,\n",
    "        dx,\n",
    "        dx_dot\n",
    "        ], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d56be9e0dc5f2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:42:32.681391Z",
     "start_time": "2024-07-03T13:42:32.677586Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_state = torch.tensor([torch.pi,0.0,0.0,0.0])\n",
    "\n",
    "initial_time = torch.tensor(0.0)\n",
    "final_time   = torch.tensor(5.0)\n",
    "\n",
    "initial_timestep = torch.tensor(5e-2)\n",
    "\n",
    "current_integrator = neuralode.integrators.AdaptiveRK76Integrator\n",
    "\n",
    "atol, rtol = torch.tensor(0.0), torch.tensor(1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13735b81340fe808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:42:34.242685Z",
     "start_time": "2024-07-03T13:42:33.243120Z"
    }
   },
   "outputs": [],
   "source": [
    "final_state, _, sha_states, sha_times, _ = current_integrator.apply(inverted_pendulum, initial_state, initial_time, final_time, initial_timestep, {'atol': atol, 'rtol': rtol}, torch.tensor(0.0), mass_cart, mass_pole, length_pole, gravity, friction_cart, friction_pole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ba53e9-e893-4304-97e3-4ad2a7a16545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:42:36.243936Z",
     "start_time": "2024-07-03T13:42:36.233506Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pendulum(pendulum_x, pendulum_y, cart_x, cart_y):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, aspect='equal')\n",
    "    ax.scatter(pendulum_x[0].item(), pendulum_y[0].item(), marker='o')\n",
    "    ax.scatter(pendulum_x[-1].item(), pendulum_y[-1].item(), marker='x')\n",
    "    ax.plot(pendulum_x.cpu().numpy(), pendulum_y.cpu().numpy())\n",
    "    ax.plot(cart_x.cpu().numpy(), cart_y.cpu().numpy())\n",
    "    for cx, cy, wx, wy in zip(cart_x, cart_y, pendulum_x, pendulum_y):\n",
    "        ax.plot([cx.item(), wx.item()], [cy.item(), wy.item()], linewidth=0.25, linestyle='--', color='k')\n",
    "    ax.scatter(cart_x[0].item(), 0.0, marker='o')\n",
    "    ax.scatter(cart_x[-1].item(), 0.0, marker='x')\n",
    "    ax.axhline(cart_y.cpu().mean(), linewidth=0.5, color='k')\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    return fig, ax\n",
    "\n",
    "def animate_pendulum(pendulum_x, pendulum_y, cart_x, cart_y, system_times, frame_time=1000/60):\n",
    "    plt.ioff()\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, aspect='equal')\n",
    "\n",
    "    t_initial, t_final = system_times.min().item(), system_times.max().item()\n",
    "    frame_times = np.linspace(t_initial, t_final, int(1000*(t_final - t_initial)/frame_time+0.5))\n",
    "\n",
    "    pendulum_x = np.interp(frame_times, system_times.cpu().numpy(), pendulum_x.cpu().numpy())\n",
    "    pendulum_y = np.interp(frame_times, system_times.cpu().numpy(), pendulum_y.cpu().numpy())\n",
    "    cart_x = np.interp(frame_times, system_times.cpu().numpy(), cart_x.cpu().numpy())\n",
    "    cart_y = np.interp(frame_times, system_times.cpu().numpy(), cart_y.cpu().numpy())\n",
    "    \n",
    "    pole_plot, = ax.plot([cart_x[0], pendulum_x[0].item()], [cart_y[0], pendulum_y[0]], linewidth=0.25, linestyle='--', color='k')\n",
    "    pendulum_head_plot, = ax.plot(pendulum_x[0], pendulum_y[0], marker='o')\n",
    "    cart_plot, = ax.plot(cart_x[0], cart_y[0], marker='o')\n",
    "    ax.axhline(cart_y.mean(), linewidth=0.5, color='k')\n",
    "    \n",
    "    def animate(frame_index):\n",
    "        pole_plot.set_data([cart_x[frame_index], pendulum_x[frame_index]], [cart_y[frame_index], pendulum_y[frame_index].item()])\n",
    "        pendulum_head_plot.set_data([pendulum_x[frame_index]], [pendulum_y[frame_index]])\n",
    "        cart_plot.set_data([cart_x[frame_index]], [cart_y[frame_index]])\n",
    "        \n",
    "    ani = animation.FuncAnimation(fig, animate, frames=cart_x.shape[0], interval=frame_time)\n",
    "    ax.set_xlim(-2.5, 2.5)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    html_ani = ani.to_html5_video()\n",
    "\n",
    "    plt.close(fig)\n",
    "    plt.ion()\n",
    "    return html_ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a85182ae572109a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:42:37.109703Z",
     "start_time": "2024-07-03T13:42:36.937497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAGiCAYAAABkuvUyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjGElEQVR4nO3df3BU9f3v8dcGYUMguxRIsgluMGqv0YIB+WXSVqJGA/VaM6UOWu/w44vYWrBimPoljoVB6uRr1cqoKFKraCuVWgta6rVi+DVqEAH3a3UkIwomBjbhh+ySpWxisvcPrus3JQmfsDnnZOH5mDkz3ZPPyb7dccyzZ8+edcVisZgAAABOIcXpAQAAQHIgGgAAgBGiAQAAGCEaAACAEaIBAAAYIRoAAIARogEAABghGgAAgBGiAQAAGCEaAACAEUujobKyUuPGjVN6eroyMzNVVlammpqaUx730ksvKT8/X6mpqRo5cqRee+01K8cEAAAGLI2GzZs3a86cOdq6davWr1+vlpYWXXvttYpEIp0e88477+jmm2/WrFmz9P7776usrExlZWX68MMPrRwVAACcgsvOL6w6cOCAMjMztXnzZl1xxRUdrpk6daoikYjWrVsX33f55Zdr1KhRWr58uV2jAgCAf3OOnU8WCoUkSYMHD+50TXV1tcrLy9vtKy0t1dq1aztcH41GFY1G44/b2tp0+PBhDRkyRC6XK/GhAQA4g8ViMR09elQ5OTlKSen6DQjboqGtrU3z5s3Td7/7XY0YMaLTdcFgUFlZWe32ZWVlKRgMdri+srJSixcv7tFZAQA429TV1encc8/tco1t0TBnzhx9+OGHeuutt3r091ZUVLQ7MxEKhZSbm6u6ujp5PJ4efS4AAM404XBYfr9f6enpp1xrSzTMnTtX69at05YtW05ZMT6fTw0NDe32NTQ0yOfzdbje7XbL7XaftN/j8RANAAAYMnlL39JPT8RiMc2dO1dr1qzRhg0blJeXd8pjCgsLVVVV1W7f+vXrVVhYaNWYAADAgKVnGubMmaNVq1bplVdeUXp6evy6BK/Xq/79+0uSpk2bpmHDhqmyslKSdOedd2rixIl6+OGHdd111+nFF1/U9u3btWLFCitHBQAAp2DpmYYnn3xSoVBIxcXFys7Ojm+rV6+Or6mtrdX+/fvjj4uKirRq1SqtWLFCBQUF+stf/qK1a9d2efEkAACwnq33abBDOByW1+tVKBTimgYAAE6hO383+e4JAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYMTSaNiyZYuuv/565eTkyOVyae3atV2u37Rpk1wu10lbMBi0ckwAAGDA0miIRCIqKCjQsmXLunVcTU2N9u/fH98yMzMtmhAAAJg6x8pfPnnyZE2ePLnbx2VmZmrQoEE9PxAAADhtvfKahlGjRik7O1vXXHON3n777S7XRqNRhcPhdhsAAOh5vSoasrOztXz5cr388st6+eWX5ff7VVxcrJ07d3Z6TGVlpbxeb3zz+/02TgwAwNnDFYvFYrY8kculNWvWqKysrFvHTZw4Ubm5ufrDH/7Q4c+j0aii0Wj8cTgclt/vVygUksfjSWRkAADOeOFwWF6v1+jvpqXXNPSE8ePH66233ur05263W26328aJAAA4O/Wqtyc6EggElJ2d7fQYAACc9Sw909DU1KTdu3fHH+/Zs0eBQECDBw9Wbm6uKioqVF9fr+eff16StHTpUuXl5ek73/mOjh8/rqefflobNmzQG2+8YeWYAADAgKXRsH37dl155ZXxx+Xl5ZKk6dOna+XKldq/f79qa2vjP29ubtb8+fNVX1+vtLQ0XXrppXrzzTfb/Q4AAOAM2y6EtEt3LugAAOBs152/m73+mgYAANA7EA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjFgaDVu2bNH111+vnJwcuVwurV279pTHbNq0SZdddpncbrcuvPBCrVy50soRAQCAIUujIRKJqKCgQMuWLTNav2fPHl133XW68sorFQgENG/ePN166636xz/+YeWYAADAwDlW/vLJkydr8uTJxuuXL1+uvLw8Pfzww5Kkiy++WG+99ZYeeeQRlZaWWjUmAAAw0KuuaaiurlZJSUm7faWlpaquru70mGg0qnA43G4DAAA9r1dFQzAYVFZWVrt9WVlZCofD+te//tXhMZWVlfJ6vfHN7/fbMSoAAGedXhUNp6OiokKhUCi+1dXVOT0SAABnJEuvaegun8+nhoaGdvsaGhrk8XjUv3//Do9xu91yu912jAcAwFmtV51pKCwsVFVVVbt969evV2FhoUMTAQCAr1kaDU1NTQoEAgoEApJOfKQyEAiotrZW0om3FqZNmxZf/7Of/UyfffaZ7r77bu3atUtPPPGE/vznP+uuu+6yckwAAGDA0mjYvn27Ro8erdGjR0uSysvLNXr0aC1cuFCStH///nhASFJeXp7+/ve/a/369SooKNDDDz+sp59+mo9bAgDQC7hisVjM6SF6UjgcltfrVSgUksfjcXocAAB6te783exV1zQAAIDei2gAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARogGAABghGgAAABGiAYAAGCEaAAAAEaIBgAAYIRoAAAARmyJhmXLlum8885TamqqJkyYoG3btnW6duXKlXK5XO221NRUO8YEAABdsDwaVq9erfLyci1atEg7d+5UQUGBSktL1djY2OkxHo9H+/fvj2+ff/651WMCAIBTsDwafvvb32r27NmaOXOmLrnkEi1fvlxpaWl65plnOj3G5XLJ5/PFt6ysrE7XRqNRhcPhdhsAAOh5lkZDc3OzduzYoZKSkm+eMCVFJSUlqq6u7vS4pqYmDR8+XH6/XzfccIM++uijTtdWVlbK6/XGN7/f36P/DAAA4ARLo+HgwYNqbW096UxBVlaWgsFgh8dcdNFFeuaZZ/TKK6/oj3/8o9ra2lRUVKQvvviiw/UVFRUKhULxra6ursf/OQAAgHSO0wP8u8LCQhUWFsYfFxUV6eKLL9ZTTz2lJUuWnLTe7XbL7XbbOSIAAGclS880DB06VH369FFDQ0O7/Q0NDfL5fEa/o2/fvho9erR2795txYgAAMCQpdHQr18/jRkzRlVVVfF9bW1tqqqqanc2oSutra365z//qezsbKvGBAAABix/e6K8vFzTp0/X2LFjNX78eC1dulSRSEQzZ86UJE2bNk3Dhg1TZWWlJOm+++7T5ZdfrgsvvFBHjhzRgw8+qM8//1y33nqr1aMCAIAuWB4NU6dO1YEDB7Rw4UIFg0GNGjVKr7/+evziyNraWqWkfHPC48svv9Ts2bMVDAb1rW99S2PGjNE777yjSy65xOpRAQBAF1yxWCzm9BA9KRwOy+v1KhQKyePxOD0OAAC9Wnf+bvLdEwAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADAyDlODwDgzNV69KjaIhGlZGZoZ+NOHTh2QBlpGbos8zK1NR5QyoAB6pOe7vSYAAwRDQAs0Xr0qOpuna2jjfVafEsf1fQ9FP/ZRS1DtOiFVqVnDpP/6d8RDkCSsOXtiWXLlum8885TamqqJkyYoG3btnW5/qWXXlJ+fr5SU1M1cuRIvfbaa3aMCaAHtUUiOtpYr3P2H9Scpxs0JByTJA0JxzTn6Qads/+gjjbWqy0ScXhSAKYsj4bVq1ervLxcixYt0s6dO1VQUKDS0lI1NjZ2uP6dd97RzTffrFmzZun9999XWVmZysrK9OGHH1o9KoAelJKZocW39FFwkOQ7Ii16oVX/64uYFr3QKt8RKThIuu+Wc5SSmeHsoACMuWKxWMzKJ5gwYYLGjRunxx9/XJLU1tYmv9+vO+64QwsWLDhp/dSpUxWJRLRu3br4vssvv1yjRo3S8uXLT1ofjUYVjUbjj8PhsPx+v0KhkDwejwX/RABMvBd8T//xj//QkPA3ofC14CBp8S19dMjj0jOlz2icb5xTYwJnvXA4LK/Xa/R309JrGpqbm7Vjxw5VVFTE96WkpKikpETV1dUdHlNdXa3y8vJ2+0pLS7V27doO11dWVmrx4sUn7Z86dar69u17+sMDSEjDsQZ9fuhzfS7pJ8elL2uOSpKKBgzUxy6XIs+cWDf3D3OVlZbl3KDAWa6lpcV4raXRcPDgQbW2tiorq/1/ELKysrRr164OjwkGgx2uDwaDHa6vqKhoFxlfn2lYvXo1ZxoAB/37mYZlA76QJC0591wFvd+caXi89HHONAAO+vpMg4mkv0+D2+2Wx+NptwFw3mWZl8U/JeE7Im2O/kvr+vyr3TUO+S1DdVnmZQ5PCsCUpdEwdOhQ9enTRw0NDe32NzQ0yOfzdXiMz+fr1noAvVNb44F2Fz2mjE2Te9SAdhdHLnzhK7U1HnB2UADGLI2Gfv36acyYMaqqqorva2trU1VVlQoLCzs8prCwsN16SVq/fn2n6wH0TikDBig9c5i+yh6qZbdm6dAnxxT5KKJDHpeeuNWnr7KHKj1zmFIGDHB6VACGLL+5U3l5uaZPn66xY8dq/PjxWrp0qSKRiGbOnClJmjZtmoYNG6bKykpJ0p133qmJEyfq4Ycf1nXXXacXX3xR27dv14oVK6weFUAP6pOeLv/Tv1NbJKLVmRm67v9ep+hXUf2m9Dcn7gj5v7kjJJBsLI+GqVOn6sCBA1q4cKGCwaBGjRql119/PX6xY21trVJSvjnhUVRUpFWrVunee+/VPffco29/+9tau3atRowYYfWoAHpYn/T0eBTs+2SfJMUveuzDW45A0rH8Pg12687nTQHY56qrrpIkbdiwweFJAPxP3fm7mfSfngAAAPbgC6sA2OLgwYNOjwAgQUQDAFtceumlTo8AIEFEAwBbvP32206PACBBRAMAW1x99dVOjwAgQUQDAFu88cYbTo8AIEFEAwBbXHvttU6PACBBRAMAW3CmAUh+RAMAW3CmAUh+RAMAW/DpCSD5EQ0AbDF8+HCnRwCQIKIBgC2OHj3q9AgAEkQ0ALDF8ePHnR4BQIKIBgC2yMvLc3oEAAkiGgDYIhAIOD0CgAQRDQBsUVxc7PQIABJENACwBTd3ApIf0QDAFtzcCUh+RAMAW3CmAUh+RAMAW3CmAUh+RAMAW2zZssXpEQAkiGgAYItLLrnE6REAJIhoAGCLffv2OT0CgAQRDQBskZKS4vQIABJENACwxdChQ50eAUCCiAYAtvjkk0+cHgFAgogGALb4/ve/7/QIABJENACwBTd3ApIf0QDAFtzcCUh+RAMAW3CmAUh+RAMAW3CmAUh+RAMAW2zatMnpEQAkiGgAYIuxY8c6PQKABBENAGzBfRqA5Ec0ALDFwIEDnR4BQIIsvRn84cOHdcstt8jj8WjQoEGaNWuWmpqaujymuLhYLper3fazn/3MyjEB2KB///7q37+/02MASIClZxpuueUW7d+/X+vXr1dLS4tmzpyp2267TatWreryuNmzZ+u+++6LP05LS7NyTAA2qKurc3oEAAmyLBo+/vhjvf7663rvvffiF0A99thj+sEPfqCHHnpIOTk5nR6blpYmn89n1WgAHFBYWOj0CAASZNnbE9XV1Ro0aFC7K6ZLSkqUkpKid999t8tjX3jhBQ0dOlQjRoxQRUWFjh071unaaDSqcDjcbgPQ+7zxxhvc4AlIcpadaQgGg8rMzGz/ZOeco8GDBysYDHZ63E9+8hMNHz5cOTk5+uCDD/Sf//mfqqmp0V//+tcO11dWVmrx4sU9OjuAnsfNnYDk1+1oWLBggR544IEu13z88cenPdBtt90W/98jR45Udna2rr76an366ae64IILTlpfUVGh8vLy+ONwOCy/33/azw/AGpxlAJJft6Nh/vz5mjFjRpdrzj//fPl8PjU2Nrbb/9VXX+nw4cPdul5hwoQJkqTdu3d3GA1ut1tut9v49wFwBmcagOTX7WjIyMhQRkbGKdcVFhbqyJEj2rFjh8aMGSNJ2rBhg9ra2uIhYCIQCEiSsrOzuzsqgF6kqqrK6REAJMiyCyEvvvhiTZo0SbNnz9a2bdv09ttva+7cubrpppvin5yor69Xfn6+tm3bJkn69NNPtWTJEu3YsUN79+7Vq6++qmnTpumKK67QpZdeatWoAGwwceJETZw40ekxACTA0vs0vPDCC5o7d66uvvpqpaSkaMqUKXr00UfjP29paVFNTU380xH9+vXTm2++qaVLlyoSicjv92vKlCm69957rRwTgA127tzp9AgAEuSKxWIxp4foSeFwWF6vV6FQSB6Px+lxAPx/11xzjSRp/fr1Dk8C4H/qzt9NvnsCgC1aW1udHgFAgogGALY4fPiw0yMASBDRAMAWI0aMcHoEAAkiGgDY4p133nF6BAAJIhoA2OKqq65yegQACSIaANiC20gDyY9oAGALbiMNJD+iAYAtONMAJD+iAYAtONMAJD+iAYAt3n77badHAJAgogGALTr6ansAyYVoAGCLL7/80ukRACSIaABgi5aWFqdHAJAgogGALXJzc50eAUCCiAYAtggEAk6PACBBRAMAWxQXFzs9AoAEEQ0AbMHNnYDkRzQAsAU3dwKSH9EAwBacaQCSH9EAwBacaQCSH9EAwBZbtmxxegQACSIaANjikksucXoEAAkiGgDYYt++fU6PACBBRAMAW6SkpDg9AoAEEQ0AbDF06FCnRwCQIKIBgC0++eQTp0cAkCCiAYAtvv/97zs9AoAEEQ0AbMHNnYDkRzQAsAU3dwKSH9EAwBacaQCSH9EAwBacaQCSH9EAwBYbNmxwegQACSIaANhi/PjxTo8AIEFEAwBb7Nq1y+kRACSI+7oCsM7xkBSqV2tbTOo7QM193Kr+9NCJx6H6Ez8HkDQsi4b7779fRUVFSktL06BBg4yOicViWrhwobKzs9W/f3+VlJRwFzkgWR0PSX+comMrSvWj//qzPm44pk8PNOvm323Vj/7rzzq2olT64xTCAUgilkVDc3OzbrzxRt1+++3Gx/zmN7/Ro48+quXLl+vdd9/VgAEDVFpaquPHj1s1JgCrRJt07Mug0iJ1evT4vXIda1TrsUPK1iE9evxepUXqdOzLoBRtcnpSAIYsi4bFixfrrrvu0siRI43Wx2IxLV26VPfee69uuOEGXXrppXr++ee1b98+rV271qoxAVikNT1HN7f8Sp+3ZWp4SqOuzwnJ58vSi/2WaHhKoz5vy9TNLb9Sa3qO06MCMNRrrmnYs2ePgsGgSkpK4vu8Xq8mTJig6urqTo+LRqMKh8PtNgDO27bnsP47PFA3NZ8Ih3f3RpRSuz0eDDc1/0r/HR6obXsOOz0qAEO9JhqCwaAkKSsrq93+rKys+M86UllZKa/XG9/8fr+lcwIw03j0xNuK+zVEd7X8XLXlHtWWeyRJd7X8XPs1pN06AL1ft6JhwYIFcrlcXW52f6yqoqJCoVAovtXV1dn6/AA6lpmeKknK1iE90veJdj97pO8TytahdusA9H7duk/D/PnzNWPGjC7XnH/++ac1iM/nkyQ1NDQoOzs7vr+hoUGjRo3q9Di32y23231azwnAOuPzBqvA06RHj39zDcNdLT/XI32f0PCURr3Yb4l+kfprjc8b7PSoAAx1KxoyMjKUkZFhySB5eXny+XyqqqqKR0I4HNa7777brU9gAOgd+hzdpz/1XaK05m+uYdivIbqp+VfxiyH/1HeJ+hz9nuQd5vS4AAxYdk1DbW2tAoGAamtr1draqkAgoEAgoKambz5elZ+frzVr1kiSXC6X5s2bp1//+td69dVX9c9//lPTpk1TTk6OysrKrBoTgFXcA5X2LZ+ODfDrF6m/jl/DsF9D9IvUX+vYAL/SvuWT3AMdHhSAKctuI71w4UI999xz8cejR4+WJG3cuFHFxcWSpJqaGoVC39zY5e6771YkEtFtt92mI0eO6Hvf+55ef/11pabynieQdFK90v95WWnRJv01PUfb9hxW49HjykxP1fi8wSfOMLgHnlgHICm4YrFYzOkhelI4HJbX61UoFJLH43F6HAAAerXu/N3sNR+5BAAAvRvRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMCIZdFw//33q6ioSGlpaRo0aJDRMTNmzJDL5Wq3TZo0yaoRAQBAN5xj1S9ubm7WjTfeqMLCQv3+9783Pm7SpEl69tln44/dbrcV4wEAgG6yLBoWL14sSVq5cmW3jnO73fL5fBZMBAAAEtHrrmnYtGmTMjMzddFFF+n222/XoUOHulwfjUYVDofbbQAAoOf1qmiYNGmSnn/+eVVVVemBBx7Q5s2bNXnyZLW2tnZ6TGVlpbxeb3zz+/02TgwAwNmjW9GwYMGCky5U/Pdt165dpz3MTTfdpB/+8IcaOXKkysrKtG7dOr333nvatGlTp8dUVFQoFArFt7q6utN+fgAA0LluXdMwf/58zZgxo8s1559/fiLznPS7hg4dqt27d+vqq6/ucI3b7eZiSQAAbNCtaMjIyFBGRoZVs5zkiy++0KFDh5SdnW3bcwIAgI5Zdk1DbW2tAoGAamtr1draqkAgoEAgoKampvia/Px8rVmzRpLU1NSkX/7yl9q6dav27t2rqqoq3XDDDbrwwgtVWlpq1ZgAAMCQZR+5XLhwoZ577rn449GjR0uSNm7cqOLiYklSTU2NQqGQJKlPnz764IMP9Nxzz+nIkSPKycnRtddeqyVLlvD2AwAAvYArFovFnB6iJ4XDYXm9XoVCIXk8HqfHAQCgV+vO381e9ZFLAADQexENAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwAjRAAAAjBANAADACNEAAACMEA0AAMAI0QAAAIwQDQAAwIhl0bB3717NmjVLeXl56t+/vy644AItWrRIzc3NXR53/PhxzZkzR0OGDNHAgQM1ZcoUNTQ0WDUmAAAwZFk07Nq1S21tbXrqqaf00Ucf6ZFHHtHy5ct1zz33dHncXXfdpb/97W966aWXtHnzZu3bt08/+tGPrBoTAAAYcsVisZhdT/bggw/qySef1Geffdbhz0OhkDIyMrRq1Sr9+Mc/lnQiPi6++GJVV1fr8ssvP+mYaDSqaDTa7nfk5uaqrq5OHo/Hmn8QAADOEOFwWH6/X0eOHJHX6+1y7Tk2zSTpxB/0wYMHd/rzHTt2qKWlRSUlJfF9+fn5ys3N7TQaKisrtXjx4pP2+/3+nhkaAICzwNGjR3tPNOzevVuPPfaYHnrooU7XBINB9evXT4MGDWq3PysrS8FgsMNjKioqVF5eHn/c1tamw4cPa8iQIXK5XD0yu12+rj3OktiD19tevN724zW3V7K+3rFYTEePHlVOTs4p13Y7GhYsWKAHHnigyzUff/yx8vPz44/r6+s1adIk3XjjjZo9e3Z3n7JLbrdbbre73b5/j45k4/F4kupfuGTH620vXm/78ZrbKxlf71OdYfhat6Nh/vz5mjFjRpdrzj///Pj/3rdvn6688koVFRVpxYoVXR7n8/nU3NysI0eOtPvD39DQIJ/P191RAQBAD+p2NGRkZCgjI8NobX19va688kqNGTNGzz77rFJSuv6wxpgxY9S3b19VVVVpypQpkqSamhrV1taqsLCwu6MCAIAeZNlHLuvr61VcXKzc3Fw99NBDOnDggILBYLtrE+rr65Wfn69t27ZJOnF6ZNasWSovL9fGjRu1Y8cOzZw5U4WFhR1eBHmmcbvdWrRo0Ulvt8AavN724vW2H6+5vc6G19uyj1yuXLlSM2fO7PBnXz/l3r17lZeXp40bN6q4uFjSiZs7zZ8/X3/6058UjUZVWlqqJ554grcnAABwmK33aQAAAMmL754AAABGiAYAAGCEaAAAAEaIBgAAYIRo6IVO92vFcfruv/9+FRUVKS0tLenvKNpbLVu2TOedd55SU1M1YcKE+Eet0fO2bNmi66+/Xjk5OXK5XFq7dq3TI53RKisrNW7cOKWnpyszM1NlZWWqqalxeixLEA290Ol+rThOX3Nzs2688UbdfvvtTo9yRlq9erXKy8u1aNEi7dy5UwUFBSotLVVjY6PTo52RIpGICgoKtGzZMqdHOSts3rxZc+bM0datW7V+/Xq1tLTo2muvVSQScXq0HsdHLpPEqb5WHD1j5cqVmjdvno4cOeL0KGeUCRMmaNy4cXr88cclnfhiOb/frzvuuEMLFixweLozm8vl0po1a1RWVub0KGeNAwcOKDMzU5s3b9YVV1zh9Dg9ijMNSeJUXysO9FbNzc3asWNHu6+8T0lJUUlJiaqrqx2cDLBGKBSSpDPyv9lEQxL4+mvFf/rTnzo9CtBtBw8eVGtrq7Kystrt7+or74Fk1dbWpnnz5um73/2uRowY4fQ4PY5osNGCBQvkcrm63Hbt2tXuGCu/VvxMdzqvNwAkYs6cOfrwww/14osvOj2KJbr9LZc4fVZ+rThO1t3XG9YYOnSo+vTpo4aGhnb7+cp7nGnmzp2rdevWacuWLTr33HOdHscSRIONrPxacZysO683rNOvXz+NGTNGVVVV8Yvx2traVFVVpblz5zo7HNADYrGY7rjjDq1Zs0abNm1SXl6e0yNZhmjohb7+WvHhw4fHv1b8a/w/M2vU1tbq8OHDqq2tVWtrqwKBgCTpwgsv1MCBA50d7gxQXl6u6dOna+zYsRo/fryWLl2qSCTS6TfhIjFNTU3avXt3/PGePXsUCAQ0ePBg5ebmOjjZmWnOnDlatWqVXnnlFaWnp8ev1fF6verfv7/D0/WwGHqdZ599Niapww3WmD59eoev98aNG50e7Yzx2GOPxXJzc2P9+vWLjR8/PrZ161anRzpjbdy4scN/n6dPn+70aGekzv57/eyzzzo9Wo/jPg0AAMAIb5QDAAAjRAMAADBCNAAAACNEAwAAMEI0AAAAI0QDAAAwQjQAAAAjRAMAADBCNAAAACNEAwAAMEI0AAAAI/8P6d6rrOk0d5cAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pendulum_x = torch.sin(sha_states[...,0]) * length_pole + sha_states[...,2]\n",
    "pendulum_y = torch.cos(sha_states[...,0]) * length_pole\n",
    "\n",
    "cart_x, cart_y = sha_states[...,2], torch.zeros_like(sha_states[...,2])\n",
    "\n",
    "plot_pendulum(pendulum_x, pendulum_y, cart_x, cart_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe26ae90-e947-4e98-82b4-6adca7e76d7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:42:46.468813Z",
     "start_time": "2024-07-03T13:42:38.253302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"640\" height=\"480\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAOqhtZGF0AAACrwYF//+r\n",
       "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NCByMzE5MCA3ZWQ3NTNiIC0gSC4yNjQvTVBF\n",
       "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyNCAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
       "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
       "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
       "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
       "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTEy\n",
       "IGxvb2thaGVhZF90aHJlYWRzPTIgc2xpY2VkX3RocmVhZHM9MCBucj0wIGRlY2ltYXRlPTEgaW50\n",
       "ZXJsYWNlZD0wIGJsdXJheV9jb21wYXQ9MCBjb25zdHJhaW5lZF9pbnRyYT0wIGJmcmFtZXM9MyBi\n",
       "X3B5cmFtaWQ9MiBiX2FkYXB0PTEgYl9iaWFzPTAgZGlyZWN0PTEgd2VpZ2h0Yj0xIG9wZW5fZ29w\n",
       "PTAgd2VpZ2h0cD0yIGtleWludD0yNTAga2V5aW50X21pbj0yNSBzY2VuZWN1dD00MCBpbnRyYV9y\n",
       "ZWZyZXNoPTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0w\n",
       "LjYwIHFwbWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAA\n",
       "ClpliIQAL//+9q78yytHC5UuHVl7s1Hy6Ely/YgwfWgAAAMAAAMAAAgH6i965jEt8pAAAATwAS3b\n",
       "q1fjXBKjEAVfJssmpULK9eG77AQh6z2IesFljhpPVUaF3XnJDGKJ9mWeRGjj8Xp0yC2toxsfctHL\n",
       "PTJJPx7pAtegc5AB6cwkCH6sitgo/q+dqqsGScH5dcS1wA+rnzsfIGWwX5yqZIJSbXjGpepGmGmA\n",
       "Wd2sjmKROe8fqbNJ8LjmExJwsSrWb16x9EZeqfw6/cFyMPRGOQBpx78hP5ylzX29803HxYJw4QB+\n",
       "GySUesTt/kGlU3NQRn9cVQTGUBbxMrv/rTSciAA06CgXoAAo9FwxjeRW39bmttdUJskTwpfcPHCB\n",
       "9kw777kd9Iy9EkMv+Diu6dkQ1cu44fT1ubuSP/H6B2N2nDyXGgEPOQnSo4AEr9T+wj/3oLUohJTe\n",
       "J+BjJThSWGLKIpDNsF/vBW8Adkf3cKG5wI2I0Pk2m2UWt9APOsvTruSTnBZ4/ijnJ+zrPtE3CVUx\n",
       "vJ+MfxMs3YPzQM/gNZUMJDVo2j4LEe3EwoDgovWv7GvNLeLKuwRsfRtdRwoQsAAAAwEky1IfxvNj\n",
       "tNiAXqWAACrESH8D38rP7v7rqlfS8urhsJp2uYQH4sUEfA2NtsCES9fw0IxuQBV2LpQBQnkofw9f\n",
       "S5VMfujb3M6O90EkzMzyV+BQgSmYK8vbuqvXGwU50/V2YPOgftqsdJ4czhGXWJYDeGkn8LHa0koD\n",
       "WxjmD/lY840991RTHA8PpB26WsqlSTOCyV4at3ALSK6JViN5S19gMUASe9h9G8ARc/gpjbqkTDK0\n",
       "sXQqa/FVruSRbgCorSfOU9cs14IC/jEC6+0B/GEh4i668f88ziNSWS1TWs8lca+cdF2ub3Z8Ll9k\n",
       "DIWBLmHQwQCUFxpm49hIYJtm/o8h6H5mGIjajRI+F5+C+1OUUBZnlhBcQrLXAu+MMUitRJH4ykrq\n",
       "gMGfECdxt/ASKwcxSDPGbk859Qa/zxkDw/eNI2HIjB2AlH0dgAaTNuM3ADR7pX27fx6A5rL6q5eF\n",
       "quzJHxhP7z0L5LELoXNByA/MfSwwovgqX815qpNxUNB2v5QGfZW8/RsJr+o4QqoEOEVmnfxR1qlj\n",
       "Mt6efjIPZG0eEgbaXCLeY0hM68agsmYNNTdfbROj87P4sQ81A+kmmGQPUCqocuFUdSZIxWqTh57s\n",
       "f0ehROrVYaOH+KsXw9m1aV1AhT46KuhqiSFooAqKvPTZT6q3cDx4YQ2jtnsxX0ea2LyqG+WiBZ8q\n",
       "Co5xyScsfyYvFFKD5n6vctC7nyVwCO4scG0ZRqBtqw+NlrPSey+2+q2zRBPz0q4UE5QQzn+VW+n5\n",
       "0nbGRVG/RdedQfP2eC+a+euPAizm2ocgzTZerZtHIWcKSQ/99V6nPHwe/4Qm1Ka5dvgc9pHZW1d3\n",
       "QmVoEarPkXBcDlEm1EoxFNM+5af52b6WTgd9cP2+wQ8keJwfHY11XVknzGsYABQsoryuDhczyKCW\n",
       "QMoBSGWUDR1t0cgUAQIZXZ/SQ2X8DRmRrZSRR7MLRbGKYRWArNXm/mLktHGNCJyMrSrxF3QJ4G7f\n",
       "+P4uufzabccOhfnD8ZiyuVEIevOANXT7baVzmkBAinPBpFS/1/AEqVzOHTMJEUOlIAkhFIXaw/8M\n",
       "SxggPkqWhTjpJzSr1N4Tata9xMCj0vse/0y7V3+ZLCOFYWSHMYdQ1LdjICuDWvYTFBZP2GUD6cVP\n",
       "U4tHceuRQAmkJALrDCoaU7zzzc8smkTCGoosIk0Pg6lKlTT/dXcP1evYr7cTXFN4gmoipFzXe6VE\n",
       "VasGcyISMi5+D/QVWAj8ZsW30JZScypqaHxYty+PF/wC6g+YtwMosKu/8M5gnSfxh61IR4aFznT7\n",
       "M1F6xHEykuR3ZMvgLa8nKl1SK+sUaVfKYJwQp/pjJdUM7a2RlyR9tXpJlqSyrgboepk41uE/qGjK\n",
       "lCFvtsaX266Etoz3PTXhVSoxMUfKxv8wrZyufn/f+NLaH0IYNOMZICVZeuFhkp0AnHT+BqKwyMYF\n",
       "vwYDb9vRdLUsICVhreh4fLss6v6v+luNDPIPqs3LwYEc500V2/rRQyl31ZQnh9ofgJ04aZlJWW5/\n",
       "amiEJJMY3BHHTVLf1BOIrrAUvsl06rwVMULkP6pW1wZ50V9i8kIz1LibISmjOF4vtLjFMaU3DdDh\n",
       "w9phj2X/iUxfoiCLl0S6HetkCm1mBWQ04poGw1BJfXFwQCkxe4kQAoZosVmMSh4EHZqUHEP4PPh4\n",
       "eoTbUOhZ54T8SIA2O4flEe5cEcoqXuCneLPzT1s+Ivq/YLb02suBlO9W3ugsKY1YfQnIHbWxz0N5\n",
       "Hx1XGkz5bIS+vvuHP8hbH/dLusaZkVAy3fwhU8SeH+TUzY4903u4rKYMCrNpp8eaIQKuxO/P8Ntj\n",
       "b2ou9USXSoA4bmSc3n3d3hv2RmjOGd4oKrkNiTr+31RAy2PNxQX2fBiofAmSFj7YyolYVbgI8x8U\n",
       "ogP2JR7M7xahrg+z3liY8dXkJnL72UGefq5P61qe6X4NK0KfK/CbCLao7JmxWN+hKjuQbt5afaqm\n",
       "qj6gQx0B7hABKmt8SBHSoKr4SVPYNReG/ZP/AftMGvsK2ig1XANA9lU+DQnpOza+IkoKar+tIVzQ\n",
       "6I4WGIfGFRivpuzSWfexYwK4aRFNhiS6+TcYtmnrRbweV6LaHL3IUdv5cBO93tQsQLuctUlYcYzC\n",
       "yXgInXd0Lrbsz0+7qYmndJ4dPihSphOpcaNhOQuebJVuIwp/+pw/YAvOo5urqTwGudsLXGBmhmmz\n",
       "TjIfixe2z+/Nqe9uTXqsWwEnt9fbZiN7Rony0oOl+6TxrdqNRMdAmZwV1H67CXpe+rf8OtERUoIZ\n",
       "5veeDCQkuR4lKII1+G/Nl2goNu497UbxXU4RctuPeCEzNs73F4+wdegCLrblpup+g72ph3yPv9Py\n",
       "49qgB/QP1Ei4DSeBUl+2O3/X6pXhPNuR6iwo4vq0ILCsDigeTphNMcYtRlNW8cXRSQaGy/TLtrF6\n",
       "ubp7dyCxN70tEDpa+ViqvT3cJJOP/4kGc30WZxuB1fH1o7DXRFfHAC0WyMQNQs1jdWUqx30Y0GZk\n",
       "BcBHYAUe5nmJo735K1HXvben+Ab3Z9XONETAuaD4+7aNBSOyckfsvDNaEQdVf/8cOj2rHgi+8laj\n",
       "GYhnJFJSZ59712GpZ+2ppqXYVP5yg9FDpiZ2y6QlordbtcXVD9DiUDS3salFgxvSnX04uAStrs0F\n",
       "7d9ty+Mj9tL/jdPl9rWAbjBeS6JPRvVoNgvvZC5TjE7v0zEJD8JjIUpSSmaFIICMjvGhqI6bFaHJ\n",
       "Wd1HT9Ga3feRMXBGLIGl6uVooxeNsL8qJyqcUXQ1kMNwglHPYwETTttlAaKNA0KK2h4Afs+7PL3M\n",
       "PKbY0C4GBgEA4yXXKg8PwChJ7fsgHSJnUeX1rex/BHs+LdRZ8YGbYCKdEcugJu+BwePK0auBjMwy\n",
       "Vi0wD14DHE6fahVZezDCI6+A0lDj3mTX4JgAAB+RAAAAZEGaJGxC//6MsAAONWqPXAHKKeHA03H1\n",
       "bV0q6gcBxmks23uklum9ABYsXXrTzzm6sVhDR+3UA/trVXlPHNvSElUACmltDj8JucOUgLG3Tfwz\n",
       "lYrj1/JBJNYE26DQEoxnGKQ0fOAAAAAtQZ5CeIR/AAR2Bi9qRCicIjckLI692uM+AC4t+a90jRPq\n",
       "UpXu4Xb/Ze8eCj4hAAAAHgGeYXRH/wAHQJRVIY/8ez1EX2sCQASQGG4oP+5QBAAAABYBnmNqR/8A\n",
       "AqGYSy5E+zohT5C4AAEzAAAAHUGaaEmoQWiZTAhf//6MsAAB1PW7+Mm6m9YAAA+5AAAAJEGehkUR\n",
       "LCP/AAGm3fIeO1VT9KJ4zABUL1WFTUlEjrhJQ6wNKQAAABYBnqV0R/8AAqAtrLOiqWhi1TQAAOOB\n",
       "AAAAFAGep2pH/wACoZrOMHp252QAAEHAAAAAGEGarEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nspFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGe6XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGe62pH/wACoZrOMHp252QAAEHAAAAAGEGa8EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nw5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfLXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGfL2pH/wACoZrOMHp252QAAEHAAAAAGEGbNEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n1JFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfcXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGfc2pH/wACoZrOMHp252QAAEHAAAAAGEGbeEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n5ZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGftXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGft2pH/wACoZrOMHp252QAAEHBAAAAGEGbvEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n9pFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGf+XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGf+2pH/wACoZrOMHp252QAAEHBAAAAGEGb4EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nh5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGePXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeP2pH/wACoZrOMHp252QAAEHBAAAAGEGaJEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nkJFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGeYXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeY2pH/wACoZrOMHp252QAAEHBAAAAGEGaaEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "noZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGepXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGep2pH/wACoZrOMHp252QAAEHAAAAAGEGarEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nspFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGe6XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGe62pH/wACoZrOMHp252QAAEHAAAAAGEGa8EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nw5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfLXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGfL2pH/wACoZrOMHp252QAAEHAAAAAGEGbNEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n1JFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfcXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGfc2pH/wACoZrOMHp252QAAEHAAAAAGEGbeEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n5ZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGftXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGft2pH/wACoZrOMHp252QAAEHBAAAAGEGbvEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n9pFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGf+XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGf+2pH/wACoZrOMHp252QAAEHBAAAAGEGb4EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nh5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGePXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeP2pH/wACoZrOMHp252QAAEHBAAAAGEGaJEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nkJFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGeYXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeY2pH/wACoZrOMHp252QAAEHBAAAAGEGaaEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "noZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGepXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGep2pH/wACoZrOMHp252QAAEHAAAAAGEGarEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nspFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGe6XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGe62pH/wACoZrOMHp252QAAEHAAAAAGEGa8EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nw5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfLXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGfL2pH/wACoZrOMHp252QAAEHAAAAAGEGbNEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n1JFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfcXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGfc2pH/wACoZrOMHp252QAAEHAAAAAGEGbeEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n5ZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGftXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGft2pH/wACoZrOMHp252QAAEHBAAAAGEGbvEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n9pFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGf+XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGf+2pH/wACoZrOMHp252QAAEHBAAAAGEGb4EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nh5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGePXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeP2pH/wACoZrOMHp252QAAEHBAAAAGEGaJEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nkJFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGeYXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeY2pH/wACoZrOMHp252QAAEHBAAAAGEGaaEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "noZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGepXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGep2pH/wACoZrOMHp252QAAEHAAAAAGEGarEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nspFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGe6XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGe62pH/wACoZrOMHp252QAAEHAAAAAGEGa8EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nw5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfLXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGfL2pH/wACoZrOMHp252QAAEHAAAAAGEGbNEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n1JFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfcXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGfc2pH/wACoZrOMHp252QAAEHAAAAAGEGbeEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n5ZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGftXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGft2pH/wACoZrOMHp252QAAEHBAAAAGEGbvEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n9pFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGf+XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGf+2pH/wACoZrOMHp252QAAEHBAAAAGEGb4EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nh5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGePXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeP2pH/wACoZrOMHp252QAAEHBAAAAGEGaJEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nkJFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGeYXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeY2pH/wACoZrOMHp252QAAEHBAAAAGEGaaEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "noZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGepXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGep2pH/wACoZrOMHp252QAAEHAAAAAGEGarEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nspFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGe6XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGe62pH/wACoZrOMHp252QAAEHAAAAAGEGa8EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nw5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfLXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGfL2pH/wACoZrOMHp252QAAEHAAAAAGEGbNEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n1JFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfcXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGfc2pH/wACoZrOMHp252QAAEHAAAAAGEGbeEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n5ZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGftXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGft2pH/wACoZrOMHp252QAAEHBAAAAGEGbvEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n9pFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGf+XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGf+2pH/wACoZrOMHp252QAAEHBAAAAGEGb4EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nh5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGePXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeP2pH/wACoZrOMHp252QAAEHBAAAAGEGaJEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nkJFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGeYXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeY2pH/wACoZrOMHp252QAAEHBAAAAGEGaaEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "noZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGepXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGep2pH/wACoZrOMHp252QAAEHAAAAAGEGarEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nspFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGe6XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGe62pH/wACoZrOMHp252QAAEHAAAAAGEGa8EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nw5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfLXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGfL2pH/wACoZrOMHp252QAAEHAAAAAGEGbNEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n1JFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfcXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGfc2pH/wACoZrOMHp252QAAEHAAAAAGEGbeEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n5ZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGftXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGft2pH/wACoZrOMHp252QAAEHBAAAAGEGbvEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n9pFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGf+XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGf+2pH/wACoZrOMHp252QAAEHBAAAAGEGb4EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nh5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGePXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeP2pH/wACoZrOMHp252QAAEHBAAAAGEGaJEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nkJFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGeYXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeY2pH/wACoZrOMHp252QAAEHBAAAAGEGaaEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "noZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGepXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGep2pH/wACoZrOMHp252QAAEHAAAAAGEGarEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nspFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGe6XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGe62pH/wACoZrOMHp252QAAEHAAAAAGEGa8EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nw5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfLXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGfL2pH/wACoZrOMHp252QAAEHAAAAAGEGbNEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n1JFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfcXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGfc2pH/wACoZrOMHp252QAAEHAAAAAGEGbeEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n5ZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGftXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGft2pH/wACoZrOMHp252QAAEHBAAAAGEGbvEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n9pFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGf+XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGf+2pH/wACoZrOMHp252QAAEHBAAAAGEGb4EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nh5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGePXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeP2pH/wACoZrOMHp252QAAEHBAAAAGEGaJEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nkJFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGeYXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGeY2pH/wACoZrOMHp252QAAEHBAAAAGEGaaEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "noZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGepXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGep2pH/wACoZrOMHp252QAAEHAAAAAGEGarEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nspFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGe6XRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGe62pH/wACoZrOMHp252QAAEHAAAAAGEGa8EmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "nw5FFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfLXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGfL2pH/wACoZrOMHp252QAAEHAAAAAGEGbNEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n1JFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGfcXRH/wACoC5V50VjaEgAALuA\n",
       "AAAAFAGfc2pH/wACoZrOMHp252QAAEHAAAAAGEGbeEmoQWyZTAhf//6MsAAAAwAAAwABXwAAACJB\n",
       "n5ZFFSwj/wABpt4CKJOtulUQAGIk18bNSUoHGM+RoIH1AAAAFAGftXRH/wACoC5V50VjaEgAALuB\n",
       "AAAAFAGft2pH/wACoZrOMHp252QAAEHBAAAAF0GbuUmoQWyZTAj//IQAAAMAAAMAAFBAAAALu2WI\n",
       "ggAO//73Tr8Cm0WXagOSVwr2yqQmWblSawHypgAAAwAAAwAAAwCQhHHua5XJPWaAAAAvYAliCmVA\n",
       "8Am+7AAVx1aw3yLvM+7+HIszqpt72isnYCOqCNiRXfNv9UkCnYEYOvEhB9eNro14TJKXNXhHMVv7\n",
       "0uvGEz/7Cd/H1yqkpj5beuw0Cq0cLpOMXuoBP+0yc8iPU82jPQHataATecqX20kaSuxEnDTsQvRm\n",
       "/18QKsrVByihZ8iu6aJ0jv8eWm6TP2yebyeGNYAG760izL/XEe0uCtmiT9aSD9vciiEYdU7o4D6X\n",
       "+9x+h/PjweiVC6IpmhYJw0fDRvhZ2csvG/bYKCjfAvocW+FzN2rBDp5Le58M627v/xmK93QqwABy\n",
       "r1fA4CunwiwcAALqSOXApR7f+TsKDpXKIeoAEyGwxRRTXMmePJNA7ehTd7zBNOi80xCXMQVxEAlM\n",
       "I0F73flz6UFjxZICBY7D/S+ONimZUDrJUjIrmoDZlaifbZDqnvD2QahMYhfsu9YG4DPyvm33CzHq\n",
       "oOIaXwvOqv57nFnIxISu6Uo+ZDG5LaNMxYju2Ns5TF0lMtzAlwdSctsVKmkLi9Z0vSNimP8n0OP7\n",
       "imEu+THnqON246EhHnAEYnkBM9s617R5rQ5rhLFFXq+N7Ad0MbdWvqHqaju76yfoAAADAEHjY0jW\n",
       "BGfwwAAAOXaUC3QrP8NNEyc3iwWtey4q/vQ+XIosgddBnFmb5tGsa8S6n17BvmHMDlgvmBteUIEV\n",
       "Llb4KGmM3eElHRxuNPjihyOK/mfIFt5LRt3X4O36Pu3fgV0a++46OZW44IrvaZxjXJyY9nsJIGBf\n",
       "xVRHu+n9snFCWysFnKbCQn8p0QRYmsHZ0prujFB7xXsfBDK9Z0u2GnzTL0qRlWZrSUTdnokePlBR\n",
       "AJpiKKwAWRzg2+9hSDg+Cj8X6pPxo2iNhAbgQwpPrAYFuD+09k2LB4Mr5rYcCyVkHeWjgakBnqd6\n",
       "NfQ9cDOwkvLsArFtbD/2rNbpaBoqwHWoDqwxAinnUC4FDvA34T+4iI10Wd7hZmzTYZ5yO7D4I6L+\n",
       "UpwTXLskT3hMuiTj8CT5kbJXzEZyvss58kB0smgAxYKgjRIB2g7Wo+PbzUHI1sKloRejrh+JHI4u\n",
       "pCUYCQ/ueZtRGnf+ftp9WgBh7XeLApg/fdrMwAjqRT8/GwDfODzCEZ2K60yD1KCXr7yLiUjgXRwZ\n",
       "wlkkcdZC4Lcv6dI8dLJT6K5GHGcKAsoefHTmPNlO204RnQngIyS73YFGokRPMWZqD95ibO4kCY20\n",
       "c6WV29BQlhPrtVKHrkJWPFoE2H/F6VrmTlTC4BtvSl7EP/b/XJGW48Vj7B1w3MyoSV+fPw0NBD7a\n",
       "u4VsNOwjmSJZ+1GHC+qCn3a/nye1OTSN9RqpT+RIS/FLepgFITmuDlD3/+UQhhNRrwRkLYo9HG8Z\n",
       "JAGQVNlKXPAUajKyiQKZV9e5Ibze5u/Ism5Xa+Vt1QuAPhrZ9gaMdgt9vYwY2mYOPrSJRTWsbmym\n",
       "hV9om3Df2Q/vC6FR1i+o8xh0QYC5S7iQgN67j8He5kWy4cvHnWgB78VJCFEfDDud//3//z8CKzQo\n",
       "rnv+bcdzfaubH3FJ0sfSbcuaQFVGV8rmb3gtNKxxKSwUlpvS/ms//xGEJ3ouO1tLxStIWky1pZ0i\n",
       "wiRKEVhKiVJqZySblBYO3qL7ShyaOu1DZbQAQe7GPGjIDD6xlE6iuznbEXE0F9GM8HTIO3anyURi\n",
       "pmo2EIImUkGLlNADhfc7sOUBBnbpyhTXxlxb8EzgE6U+rs5/q/lbNFZGrpHkaDib5e4oh+JrYesH\n",
       "Ddf3+Z5ItkNC7eWs5K9HRRMNUYIEawGUG2Chc9wHnLxy5Dn2JmqvKpe2FxkVrsARG4d9QV3yU4zi\n",
       "0FUCDkj/4gQEjLkmd0cKwp5kStrcIWMmKGJSnpp/h5mlr0fHbo6mvqpEeGJBdEquNLdZHfDu6C19\n",
       "h+muU5jq7W9P/gVMylMh22GO0r+ZnR5oDVe5Qz2Fu7/ofL4yDtUWTd4JaL8iH3FQVFrquHazyPTh\n",
       "sy+usjJR7DCqxGfGqsI2OtS0He/h++VTBAYqJ5CT4CzUyQgkB1L2aXcmVA9BhYx2MkjpDcn8hZqy\n",
       "tg0yy6hc6DScQezlyoTX1fV/BU8DzctUL46NIMuODVQ54ExpsqqNa6f9SX/QfXrrIrsSv5foz5cB\n",
       "XTRrKXHCHwsBltyHe0RxCplXjDIWYGIqsozGt7FThuNtoiSR5Xjhe1RzIK/JAef4NbaTk4UDh/Tj\n",
       "BpkiX6CldCSpZ3X2WTl4Ow4jFfEO3ktXsAvkhJnhc7AWBCDp03wP32wkyiuKQ79cCrSPKC2VI4tC\n",
       "SpZZiTZ/+////jfXnr/evhJ9pnHXYtA/6ongZ+kB2ovZroE7srt9XGi7o6ntZRdIPgIWS2BGx9Rl\n",
       "VCxXQsz0MrLGGV2gkKKpnilwhwM5JdA2/IrRB1sN7T4IXhi3xW/n3HyWWjTVLOF0+YPE7/DJVFwb\n",
       "WFUeQlqzQtP75ndQTZPX/wKLIWJHw9JQ0k1+ikl46aHSM6GG0gDXkJau1PWjMb41dKjVy84LK5ug\n",
       "7DJKUaP1tzKCUWB73MilCmS1Hyl8dHamsVjV06M4iqUlxNuQk+xHwheIAsUvHYVpGN9KnhA9/5dL\n",
       "CSLs4XgQd6isDgAWXvwzcKzJ/6hmB6/0kUTC2RexX+OK6/wY5auKsEByCJrocNdRAkSjE/E8AggD\n",
       "f/zv5SzNK5WaaCArDUdbqClSf/OFdRtuLFdDyg9VqbA8doliY2BUM8iMbAZb4c1XQZ5jm9f95pLO\n",
       "o/4KkiOgC+m1gkRhTypjeErhONE+NDKABliOFvsBsZIIzTdMQcmwf6pUhXqkEjq3ojLP4DMDk7nO\n",
       "pxv0lNa79gXTXxbfmjpSg56VXUPoTZE6+ONAdtzrtS+mgT/gHvmGYzLpu5WwAXvBSaQEtNoFPUdU\n",
       "a0/2PWpeETL/f21EsxnYKI8JPaAsf3AuNqF2H2nHWf+61bqXCkzfGB/ZeKrjoDTJ0iAOBo2tOfMG\n",
       "cDSyCTD5kslBdsVctkJBjMr6qusvQk7yrugHLs/8e9ga+bVcG/mvfAOXrefl6xuW2Ri224PsZfhC\n",
       "c2sA1Q2OoN2L2Ft/qctwiPfVsuJNFuGOitbN36rso7wYyjMcWY1A6j5/qDo8yXKIxdmi1mRJ3gWj\n",
       "z/WPW7ZULcbIo9Ah4ygRYyMSBHVC/bSbk9RIn4Fm43JpK/K8DXBHOu4TDH7fbPNblVzhlOYcE+OY\n",
       "3yE2ohPUqAgbvJlUKxURmxfsHiA6rRm3XE+VXwZJpVknbziKuKE5JyjYubDrEfwONwABX+OYnY1v\n",
       "qfSWKmxWVbVGFbmLx9GoICGc10luXJc6JrgdWgyuTlr/EW1WNFgiSaeSzqoAAtjj4VDSxNi5v/97\n",
       "nArsAuYd8sjaQ3fa8YIvm31hjTIWhaSujrpAibHGxTqFxiekC+PiuPiOyfcNB9HZQvN6MwBr39mo\n",
       "PN/HoWov4Qd6PdAHIoLjCrrxD2AC4EIbIY+akGAAvEpz6sMYAcX9CJAkxFHSHBzPKb/KSC87tXsz\n",
       "x/pmUxzXLTIO2m5rpd+35qUK6U/XF0f/5fmVocG+8EHY7rzaJo+UL5+Tsuwot7gzZIKx8SDGfZNJ\n",
       "kx+wbdymMo6aglZCUKQEupH1yo3W0V/8gt/wDeBthjlNC0G19YP86GGSEyrb7IAniN3lRO7Pj3uV\n",
       "3H5H2PgtxIqUazi+Rg2e9oIV15IT5jAK0X+/abtU1/Ae8pcM0/WMhITvHNteFM8Fl2RtUoehxt4X\n",
       "uBNI/5h5OIZ0dkJbN9fSBJQ5o5K6AJtzD+4JtH0rcr/OppCEQYkhKabwNtu6D9S4hlvJmDbgkuzc\n",
       "65cqRHHYHkWKHVaxAaHx7ORx0NPH4kPiJCD7wYL/Wp8fpLYvv0y3OZAHg5A1zzafIwNzcn+UgoOh\n",
       "CC18O7sbpzsKBtRtb7eEHnFEM75sxCUCZAbjS5hVQexCLYAC9wAAAEpBmiRsQv/+jLAADjtgaAHJ\n",
       "f8v+vHtkmfzA6NBJRWFGgtJ8HqmqqlPvQXVDDCVpS7XGUXtdDDGQAgPaefKlJ8d9pOuV8rncWNCX\n",
       "KAAAACZBnkJ4hH8ABJYFT6A+arwlPvpEANxUX/13oN8dF7UZ0sC+LARNwQAAABgBnmF0R/8ABz4o\n",
       "1aijbyhsfEANxbt7raEAAAAYAZ5jakf/AAKiQPuLv9vMdCQBsDpspfSAAAAAGkGaaEmoQWiZTAhf\n",
       "//6MsAAAFd9zQtIAAA6YAAAAIkGehkURLCP/AAGmvmqyy4zbVnGh+9qAPNuPwd8uNcm2ss0AAAAX\n",
       "AZ6ldEf/AAKgLe4ruXTdKswiQAsJfBwAAAAVAZ6nakf/AAKhmnaIhXaB3aAEooUHAAAAGEGarEmo\n",
       "QWyZTAhf//6MsAAAAwAAAwABXwAAAB9BnspFFSwj/wABpt33MR1OtClUQA00myyK5ttJ4JLPAAAA\n",
       "FQGe6XRH/wACoC3q31HE/aEgB5HoLwAAABUBnutqR/8AAqGadoiFdoHdoASihQcAAAAYQZrwSahB\n",
       "bJlMCF///oywAAADAAADAAFfAAAAH0GfDkUVLCP/AAGm3fcxHU60KVRADTSbLIrm20ngks4AAAAV\n",
       "AZ8tdEf/AAKgLerfUcT9oSAHkeguAAAAFQGfL2pH/wACoZp2iIV2gd2gBKKFBwAAABhBmzRJqEFs\n",
       "mUwIX//+jLAAAAMAAAMAAV8AAAAfQZ9SRRUsI/8AAabd9zEdTrQpVEANNJssiubbSeCSzgAAABUB\n",
       "n3F0R/8AAqAt6t9RxP2hIAeR6C8AAAAVAZ9zakf/AAKhmnaIhXaB3aAEooUHAAAAGEGbeEmoQWyZ\n",
       "TAhf//6MsAAAAwAAAwABXwAAAB9Bn5ZFFSwj/wABpt33MR1OtClUQA00myyK5ttJ4JLOAAAAFQGf\n",
       "tXRH/wACoC3q31HE/aEgB5HoLgAAABUBn7dqR/8AAqGadoiFdoHdoASihQcAAAAYQZu8SahBbJlM\n",
       "CF///oywAAADAAADAAFfAAAAH0Gf2kUVLCP/AAGm3fcxHU60KVRADTSbLIrm20ngks4AAAAVAZ/5\n",
       "dEf/AAKgLerfUcT9oSAHkegvAAAAFQGf+2pH/wACoZp2iIV2gd2gBKKFBwAAABhBm+BJqEFsmUwI\n",
       "X//+jLAAAAMAAAMAAV8AAAAfQZ4eRRUsI/8AAabd9zEdTrQpVEANNJssiubbSeCSzwAAABUBnj10\n",
       "R/8AAqAt6t9RxP2hIAeR6C4AAAAVAZ4/akf/AAKhmnaIhXaB3aAEooUHAAAAGEGaJEmoQWyZTAhf\n",
       "//6MsAAAAwAAAwABXwAAAB9BnkJFFSwj/wABpt33MR1OtClUQA00myyK5ttJ4JLPAAAAFQGeYXRH\n",
       "/wACoC3q31HE/aEgB5HoLwAAABUBnmNqR/8AAqGadoiFdoHdoASihQcAAAAYQZpoSahBbJlMCFf/\n",
       "/jhAAAADAAADAAVMAAAAH0GehkUVLCP/AAGm3fcxHU60KVRADTSbLIrm20ngks8AAAAVAZ6ldEf/\n",
       "AAKgLerfUcT9oSAHkeguAAAAFQGep2pH/wACoZp2iIV2gd2gBKKFBwAAABhBmqxJqEFsmUwIV//+\n",
       "OEAAAAMAAAMABUwAAAAfQZ7KRRUsI/8AAabd9zEdTrQpVEANNJssiubbSeCSzwAAABUBnul0R/8A\n",
       "AqAt6t9RxP2hIAeR6C8AAAAVAZ7rakf/AAKhmnaIhXaB3aAEooUHAAAAGEGa8EmoQWyZTAhH//3h\n",
       "AAADAAADAAAUkQAAAB9Bnw5FFSwj/wABpt33MR1OtClUQA00myyK5ttJ4JLOAAAAFQGfLXRH/wAC\n",
       "oC3q31HE/aEgB5HoLgAAABUBny9qR/8AAqGadoiFdoHdoASihQcAAAAXQZsxSahBbJlMCP/8hAAA\n",
       "AwAAAwAAUEAAABE9bW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAAE4gAAQAAAQAAAAAAAAAA\n",
       "AAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAgAAEGh0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAE4gAAAAAAAAA\n",
       "AAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAoAAAAHgAAAAAAAk\n",
       "ZWR0cwAAABxlbHN0AAAAAAAAAAEAABOIAAACAAABAAAAAA/gbWRpYQAAACBtZGhkAAAAAAAAAAAA\n",
       "AAAAAAA8AAABLABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRs\n",
       "ZXIAAAAPi21pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAA\n",
       "AAx1cmwgAAAAAQAAD0tzdGJsAAAAt3N0c2QAAAAAAAAAAQAAAKdhdmMxAAAAAAAAAAEAAAAAAAAA\n",
       "AAAAAAAAAAAAAoAB4ABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAGP//AAAANWF2Y0MBZAAf/+EAGGdkAB+s2UCgPaEAAAMAAQAAAwB4DxgxlgEABmjr48siwP34\n",
       "+AAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAAAAAAGHN0dHMAAAAAAAAAAQAAASwAAAEAAAAA\n",
       "GHN0c3MAAAAAAAAAAgAAAAEAAAD7AAAJaGN0dHMAAAAAAAABKwAAAAEAAAIAAAAAAQAABQAAAAAB\n",
       "AAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEA\n",
       "AAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAA\n",
       "AQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAA\n",
       "AAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIA\n",
       "AAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAA\n",
       "AAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAA\n",
       "AAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAA\n",
       "AQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAAB\n",
       "AAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEA\n",
       "AAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAA\n",
       "BQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAAB\n",
       "AAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAA\n",
       "AAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAA\n",
       "AAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAA\n",
       "AAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAA\n",
       "AQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAAB\n",
       "AAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEA\n",
       "AAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAA\n",
       "AgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAF\n",
       "AAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEA\n",
       "AAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAA\n",
       "AAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAA\n",
       "AAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAA\n",
       "AQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAAB\n",
       "AAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEA\n",
       "AAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAA\n",
       "AAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAAC\n",
       "AAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUA\n",
       "AAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAA\n",
       "AAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAA\n",
       "AAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAA\n",
       "AQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAAB\n",
       "AAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEA\n",
       "AAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAA\n",
       "AQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAIAAAIAAAAAAQAABQAAAAABAAAC\n",
       "AAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUA\n",
       "AAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAA\n",
       "AAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAA\n",
       "AAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAA\n",
       "AQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAAB\n",
       "AAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEA\n",
       "AAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAgAAAAAcc3RzYwAAAAAAAAABAAAAAQAA\n",
       "ASwAAAABAAAExHN0c3oAAAAAAAAAAAAAASwAAA0RAAAAaAAAADEAAAAiAAAAGgAAACEAAAAoAAAA\n",
       "GgAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAc\n",
       "AAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgA\n",
       "AAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAA\n",
       "ACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAA\n",
       "GAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAm\n",
       "AAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgA\n",
       "AAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAA\n",
       "ABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAA\n",
       "HAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAY\n",
       "AAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwA\n",
       "AAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAA\n",
       "ABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAA\n",
       "JgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAY\n",
       "AAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYA\n",
       "AAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAA\n",
       "ABwAAAAmAAAAGAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAA\n",
       "GAAAABgAAAAcAAAAJgAAABgAAAAYAAAAHAAAACYAAAAYAAAAGAAAABwAAAAmAAAAGAAAABgAAAAb\n",
       "AAALvwAAAE4AAAAqAAAAHAAAABwAAAAeAAAAJgAAABsAAAAZAAAAHAAAACMAAAAZAAAAGQAAABwA\n",
       "AAAjAAAAGQAAABkAAAAcAAAAIwAAABkAAAAZAAAAHAAAACMAAAAZAAAAGQAAABwAAAAjAAAAGQAA\n",
       "ABkAAAAcAAAAIwAAABkAAAAZAAAAHAAAACMAAAAZAAAAGQAAABwAAAAjAAAAGQAAABkAAAAcAAAA\n",
       "IwAAABkAAAAZAAAAHAAAACMAAAAZAAAAGQAAABsAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGF1ZHRh\n",
       "AAAAWW1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALGlsc3QAAAAk\n",
       "qXRvbwAAABxkYXRhAAAAAQAAAABMYXZmNjEuMS4xMDA=\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(animate_pendulum(pendulum_x, pendulum_y, cart_x, cart_y, sha_times, frame_time=1000/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fda06dbda602eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:43:05.765859Z",
     "start_time": "2024-07-03T13:43:05.757650Z"
    }
   },
   "outputs": [],
   "source": [
    "max_force = torch.tensor(240.0)\n",
    "\n",
    "# we define our network as a subclass of torch.nn.Module\n",
    "# This allows PyTorch to appropriately track parameters\n",
    "class CartPoleNet(torch.nn.Module):\n",
    "    def __init__(self, num_hidden_neurons=256, num_hidden_layers=4):\n",
    "        # First we initialise the superclass, `torch.nn.Module`\n",
    "        super().__init__()\n",
    "        # Then we define the actual neural network\n",
    "        # Most Neural Networks operate sequentially so they can be wrapped\n",
    "        # inside a torch.nn.Sequential which takes each layer\n",
    "        # as an argument.\n",
    "        # Since we're only learning one matrix, we have\n",
    "        # one layer, the `torch.nn.Linear`.\n",
    "        # `torch.nn.Linear` stores a matrix and a bias which actually makes it\n",
    "        # an Affine transformation rather than a purely linear transformation\n",
    "        hidden_layers = itertools.chain.from_iterable([(torch.nn.Linear(num_hidden_neurons, num_hidden_neurons), torch.nn.Tanh()) for _ in range(num_hidden_layers)])\n",
    "        \n",
    "        self.internal_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(6, num_hidden_neurons),\n",
    "            torch.nn.Tanh(),\n",
    "            *hidden_layers,\n",
    "            torch.nn.Linear(num_hidden_neurons, 1, bias=False),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # Our network only depends on x, but since it could also depend on t, we have\n",
    "        # included it for completeness\n",
    "        # Additionally, PyTorch layers and modules expect a batched tensor\n",
    "        # ie. a tensor where the first dimension is over different samples\n",
    "        # Since we don't depend on batches, we check if the input is 1-dimensional\n",
    "        # And add a batch dimension as needed for the internal module\n",
    "        cos_angle, sin_angle = torch.cos(x[...,0]), torch.sin(x[...,0])\n",
    "        encoded_state = torch.stack(\n",
    "            [cos_angle, sin_angle, -x[...,1]*sin_angle, x[...,1]*cos_angle, x[...,2], x[...,3]],\n",
    "        dim=-1)\n",
    "        if x.dim() == 1:\n",
    "            return self.internal_net(encoded_state[None])[0]*max_force\n",
    "        else:\n",
    "            return self.internal_net(encoded_state)*max_force\n",
    "        \n",
    "cart_pole_net = CartPoleNet()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight, gain=0.25)\n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.normal_(m.bias, std=0.1)\n",
    "\n",
    "cart_pole_net.apply(init_weights)\n",
    "\n",
    "def nn_controlled_pendulum(state, time, mc, mp, l, g, mu_c, mu_p, *args):\n",
    "    force = cart_pole_net(state, time)[...,0]\n",
    "    return inverted_pendulum(state, time, force, mc, mp, l, g, mu_c, mu_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50aa1ee4459bb31b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:43:07.723300Z",
     "start_time": "2024-07-03T13:43:06.296091Z"
    }
   },
   "outputs": [],
   "source": [
    "# As the goal is balancing the pole on top of the cart, we generate several initial states where the pole\n",
    "# is near vertical and moving with some random rotational velocity. This way, the neural network observes\n",
    "# multiple states near the vertical state where it needs to learn to counter-balance it.\n",
    "\n",
    "state_min = torch.tensor([-torch.pi*1e-1, -1e-2*torch.pi/(final_time - initial_time), 0.0, 0.0])\n",
    "state_max = torch.tensor([ torch.pi*1e-1,  1e-2*torch.pi/(final_time - initial_time), 0.0, 0.0])\n",
    "state_dataset = torch.rand(127, 4) * (state_max - state_min)[None] + state_min[None]\n",
    "# Additionally, we want to include the state where the pendulum is hanging below the cart so that the network\n",
    "# can learn how to swing the pendulum back over the cart\n",
    "state_dataset = torch.cat([state_dataset, initial_state[None]], dim=0)\n",
    "# state_dataset = initial_state[None]\n",
    "\n",
    "def batched_integrator(x0):\n",
    "    return current_integrator.apply(nn_controlled_pendulum, x0, initial_time, final_time, initial_timestep, {'atol': atol, 'rtol': rtol}, mass_cart, mass_pole, length_pole, gravity, friction_cart, friction_pole, *cart_pole_net.parameters())\n",
    "\n",
    "# First, we'll create an `optimiser` following pytorch convention\n",
    "optimiser = torch.optim.Adam(cart_pole_net.parameters(), lr=1e-2, amsgrad=True)\n",
    "# # Whenever the loss plateaus, we can reduce the learning rate to improve convergence\n",
    "lr_on_plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, patience=10)\n",
    "\n",
    "def pendulum_closure(minibatch):\n",
    "    optimiser.zero_grad()\n",
    "    \n",
    "    states = minibatch['states']\n",
    "    \n",
    "    final_state, _, intermediate_states, intermediate_times, _ = batched_integrator(states)\n",
    "\n",
    "    error = (intermediate_states[1:].square().sum(dim=-1) * intermediate_times.detach().diff(dim=-1)[:,None]).sum(dim=0).mean()\n",
    "    \n",
    "    if error.requires_grad:\n",
    "        error.backward()\n",
    "    return error\n",
    "\n",
    "# We need to set the size of our mini-batches\n",
    "batch_size = 32\n",
    "\n",
    "# Now we need an optimisation `loop` where we will take steps to minimise the error\n",
    "number_of_gd_steps = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a1e5510284b350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:43:08.761473Z",
     "start_time": "2024-07-03T13:43:08.754896Z"
    }
   },
   "outputs": [],
   "source": [
    "class PID(torch.nn.Module):\n",
    "    def __init__(self, target_state, p, i, d):\n",
    "        super().__init__()\n",
    "        self.target_state = torch.nn.Parameter(torch.as_tensor(target_state), requires_grad=False)\n",
    "        self.p = torch.nn.Parameter(torch.as_tensor(p))\n",
    "        self.i = torch.nn.Parameter(torch.as_tensor(i))\n",
    "        self.d = torch.nn.Parameter(torch.as_tensor(d))\n",
    "        self.integral = torch.tensor(0.0)\n",
    "        self.derivative = torch.tensor(0.0)\n",
    "        self.prev_error = torch.tensor(0.0)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        error = state - self.target_state\n",
    "        self.integral = self.integral + error.detach()\n",
    "        self.derivative = error.detach() - self.prev_error\n",
    "        self.prev_error = error.detach()\n",
    "        pid = (self.p * error + self.i * self.integral + self.d * self.derivative)[...,0]\n",
    "        \n",
    "        return torch.sigmoid(pid)*max_force\n",
    "\n",
    "pid_controller = PID(torch.tensor([0.0,0.0,0.0,0.0]), 0.1, 0.01, 0.5)\n",
    "\n",
    "def pid_controlled_pendulum(state, time, mc, mp, l, g, mu_c, mu_p, *args):\n",
    "    force = pid_controller(state)\n",
    "    return inverted_pendulum(state, time, force, mc, mp, l, g, mu_c, mu_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cba6d6a23e51aa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:56:02.639518Z",
     "start_time": "2024-07-03T13:43:09.519979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1024 - 0.01] Epoch Error: 7927985.093597                                                                                     \n",
      "[2/1024]/[32/128] Batch Error: 819409.952572\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, state_dataset\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], batch_size):\n\u001b[0;32m     10\u001b[0m     batch_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m'\u001b[39m: state_dataset[shuffled_indices][batch_idx:batch_idx\u001b[38;5;241m+\u001b[39mbatch_size],\n\u001b[0;32m     12\u001b[0m     }\n\u001b[1;32m---> 14\u001b[0m     step_error \u001b[38;5;241m=\u001b[39m \u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpendulum_closure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     epoch_error \u001b[38;5;241m=\u001b[39m epoch_error \u001b[38;5;241m+\u001b[39m step_error\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m*\u001b[39mbatch_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber_of_gd_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]/[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_dataset\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Batch Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_error\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\optim\\adam.py:148\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 148\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    151\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, state_dataset\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], batch_size):\n\u001b[0;32m     10\u001b[0m     batch_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m'\u001b[39m: state_dataset[shuffled_indices][batch_idx:batch_idx\u001b[38;5;241m+\u001b[39mbatch_size],\n\u001b[0;32m     12\u001b[0m     }\n\u001b[1;32m---> 14\u001b[0m     step_error \u001b[38;5;241m=\u001b[39m optimiser\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mpendulum_closure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m     epoch_error \u001b[38;5;241m=\u001b[39m epoch_error \u001b[38;5;241m+\u001b[39m step_error\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m*\u001b[39mbatch_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumber_of_gd_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]/[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_dataset\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Batch Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_error\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m, in \u001b[0;36mpendulum_closure\u001b[1;34m(minibatch)\u001b[0m\n\u001b[0;32m     28\u001b[0m error \u001b[38;5;241m=\u001b[39m (intermediate_states[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39msquare()\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m intermediate_times\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mdiff(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[:,\u001b[38;5;28;01mNone\u001b[39;00m])\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m---> 31\u001b[0m     \u001b[43merror\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m error\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\_tensor.py:516\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\overrides.py:1619\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[1;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[0;32m   1616\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[0;32m   1618\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[1;32m-> 1619\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1621\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\utils\\_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\autograd\\function.py:301\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m     )\n\u001b[0;32m    300\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\integrators\\integrators.py:114\u001b[0m, in \u001b[0;36mget_integrator.<locals>.__internal_backward\u001b[1;34m(ctx, d_c_state, d_c_time, d_intermediate_states, d_intermediate_times, d_error_in_state)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(d_inter_state \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m):\n\u001b[0;32m    112\u001b[0m             \u001b[38;5;66;03m# No need to integrate up to the boundary if the incoming gradients are zero\u001b[39;00m\n\u001b[0;32m    113\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m         current_adj_state, current_adj_time, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m__integrator_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjoint_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mcurrent_adj_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mcurrent_adj_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mnext_adj_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mintegrator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_dynamic_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m         current_adj_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mscatter(current_adj_state, \u001b[38;5;241m0\u001b[39m, adj_indices, d_inter_state\u001b[38;5;241m.\u001b[39mravel())\n\u001b[0;32m    122\u001b[0m final_adj_state, final_adj_time, _, _, _ \u001b[38;5;241m=\u001b[39m __integrator_type\u001b[38;5;241m.\u001b[39mapply(adjoint_fn, current_adj_state,\n\u001b[0;32m    123\u001b[0m                                                                    current_adj_time, t0, \u001b[38;5;241m-\u001b[39mdt, integrator_kwargs,\n\u001b[0;32m    124\u001b[0m                                                                    \u001b[38;5;241m*\u001b[39madditional_dynamic_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\autograd\\function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m     )\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\integrators\\integrators.py:35\u001b[0m, in \u001b[0;36mget_integrator.<locals>.__internal_forward\u001b[1;34m(forward_fn, x0, t0, t1, dt, integrator_kwargs, *additional_dynamic_args)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__internal_forward\u001b[39m(forward_fn: typing\u001b[38;5;241m.\u001b[39mCallable[[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor, typing\u001b[38;5;241m.\u001b[39mAny], torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[0;32m     25\u001b[0m                        x0: torch\u001b[38;5;241m.\u001b[39mTensor, t0: torch\u001b[38;5;241m.\u001b[39mTensor, t1: torch\u001b[38;5;241m.\u001b[39mTensor, dt: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m     26\u001b[0m                        integrator_kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor], \u001b[38;5;241m*\u001b[39madditional_dynamic_args):\n\u001b[0;32m     27\u001b[0m     integrator_spec \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     28\u001b[0m         __integrator_type\u001b[38;5;241m.\u001b[39mintegrator_tableau\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mto(x0\u001b[38;5;241m.\u001b[39mdevice, x0\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[0;32m     29\u001b[0m         __integrator_type\u001b[38;5;241m.\u001b[39mis_adaptive,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m         __integrator_type\u001b[38;5;241m.\u001b[39muse_local_extrapolation\n\u001b[0;32m     33\u001b[0m         )\n\u001b[1;32m---> 35\u001b[0m     c_state, c_time, intermediate_states, intermediate_times, error_in_state \u001b[38;5;241m=\u001b[39m \u001b[43mroutines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_ivp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrator_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrator_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_dynamic_args\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c_state, c_time, intermediate_states, intermediate_times, error_in_state\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\integrators\\routines.py:148\u001b[0m, in \u001b[0;36msolve_ivp\u001b[1;34m(forward_fn, integrator_specification, x0, t0, t1, dt, integrator_kwargs, additional_dynamic_args)\u001b[0m\n\u001b[0;32m    145\u001b[0m     intermediate_states\u001b[38;5;241m.\u001b[39mappend(c_state \u001b[38;5;241m+\u001b[39m truncated_bits_state)\n\u001b[0;32m    146\u001b[0m     intermediate_times\u001b[38;5;241m.\u001b[39mappend(c_time \u001b[38;5;241m+\u001b[39m truncated_bits_time)\n\u001b[1;32m--> 148\u001b[0m delta_state_lower, delta_state_upper, delta_time \u001b[38;5;241m=\u001b[39m \u001b[43mhelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtruncated_bits_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtruncated_bits_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mt1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtruncated_bits_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtableau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m delta_state \u001b[38;5;241m=\u001b[39m delta_state_upper \u001b[38;5;28;01mif\u001b[39;00m use_local_extrapolation \u001b[38;5;28;01melse\u001b[39;00m delta_state_lower\n\u001b[0;32m    157\u001b[0m c_state, truncated_bits_state \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mpartial_compensated_sum(\n\u001b[0;32m    158\u001b[0m     delta_state, (c_state, truncated_bits_state)\n\u001b[0;32m    159\u001b[0m )\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\integrators\\helpers.py:81\u001b[0m, in \u001b[0;36mcompute_step\u001b[1;34m(fn, state, time, step, tableau, additional_dynamic_args, intermediate_stages, is_adaptive)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(intermediate_stages\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     80\u001b[0m     c_coeff, a_coeff \u001b[38;5;241m=\u001b[39m tableau[stage_index][\u001b[38;5;241m0\u001b[39m], tableau[stage_index][\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mstate\u001b[38;5;241m.\u001b[39mdim())\n\u001b[1;32m---> 81\u001b[0m     intermediate_stages[stage_index] \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# We use `compensated_sum` instead of `sum` to avoid truncation at each stage calculation\u001b[39;49;00m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompensated_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_coeff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mintermediate_stages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc_coeff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_dynamic_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m lower_order_estimate \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m*\u001b[39m util\u001b[38;5;241m.\u001b[39mcompensated_sum(tableau[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39mstate\u001b[38;5;241m.\u001b[39mdim()) \u001b[38;5;241m*\u001b[39m intermediate_stages)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# To have a valid value, we set `higher_order_estimate` to the same value as `lower_order_estimate`\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Further down, this will simplify the code as we won't have to account for invalid values\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\integrators\\helpers.py:106\u001b[0m, in \u001b[0;36mconstruct_adjoint_fn.<locals>.adjoint_fn\u001b[1;34m(packed_state, adj_time, *dynamic_args)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstruct_adjoint_fn\u001b[39m(forward_fn: signatures\u001b[38;5;241m.\u001b[39mintegration_fn_signature,\n\u001b[0;32m    103\u001b[0m                          state_shape: \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m signatures\u001b[38;5;241m.\u001b[39mintegration_fn_signature:\n\u001b[0;32m    104\u001b[0m     state_size \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mprod(state_shape)\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjoint_fn\u001b[39m(packed_state: torch\u001b[38;5;241m.\u001b[39mTensor, adj_time: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m    107\u001b[0m                    \u001b[38;5;241m*\u001b[39mdynamic_args: \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;66;03m# Unpack the state variables\u001b[39;00m\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    110\u001b[0m             packed_state \u001b[38;5;241m=\u001b[39m packed_state\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_error = torch.inf\n",
    "best_params = copy.deepcopy(cart_pole_net.state_dict())\n",
    "\n",
    "cart_pole_net.train()\n",
    "\n",
    "for step in range(number_of_gd_steps):\n",
    "    epoch_error = 0.0\n",
    "    shuffled_indices = torch.randperm(state_dataset.shape[0])\n",
    "    for batch_idx in range(0, state_dataset.shape[0], batch_size):\n",
    "        batch_dict = {\n",
    "            'states': state_dataset[shuffled_indices][batch_idx:batch_idx+batch_size],\n",
    "        }\n",
    "    \n",
    "        step_error = optimiser.step(lambda: pendulum_closure(batch_dict))\n",
    "        epoch_error = epoch_error + step_error.item()*batch_dict['states'].shape[0]\n",
    "        print(f\"[{step+1}/{number_of_gd_steps}]/[{batch_idx}/{state_dataset.shape[0]}] Batch Error: {step_error:.6f}\", end='\\r')\n",
    "    epoch_error = epoch_error/state_dataset.shape[0]\n",
    "    if epoch_error < best_error:\n",
    "        best_error = epoch_error\n",
    "        best_params = copy.deepcopy(cart_pole_net.state_dict())\n",
    "    lr_on_plateau.step(epoch_error)\n",
    "    print(\" \"*128, end=\"\\r\")\n",
    "    print(f\"[{step+1}/{number_of_gd_steps} - {lr_on_plateau.get_last_lr()[0]}] Epoch Error: {epoch_error:.6f}\")\n",
    "    # If the step size is too small, then we can interrupt the\n",
    "    # training as it will not lead to significant improvements\n",
    "    if lr_on_plateau.get_last_lr()[0] < 1e-6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcd7c171910e2c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:56:15.187244Z",
     "start_time": "2024-07-03T13:56:04.122211Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m cart_pole_net\u001b[38;5;241m.\u001b[39mload_state_dict(best_params)\n\u001b[0;32m      2\u001b[0m cart_pole_net\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m----> 4\u001b[0m final_state, _, sha_states, sha_times, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcurrent_integrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_controlled_pendulum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_timestep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43matol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmass_cart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmass_pole\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_pole\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgravity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfriction_cart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfriction_pole\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m cart_pole_net(sha_states, sha_times)\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\autograd\\function.py:598\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    597\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m     )\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\integrators\\integrators.py:35\u001b[0m, in \u001b[0;36mget_integrator.<locals>.__internal_forward\u001b[1;34m(forward_fn, x0, t0, t1, dt, integrator_kwargs, *additional_dynamic_args)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__internal_forward\u001b[39m(forward_fn: typing\u001b[38;5;241m.\u001b[39mCallable[[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor, typing\u001b[38;5;241m.\u001b[39mAny], torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[0;32m     25\u001b[0m                        x0: torch\u001b[38;5;241m.\u001b[39mTensor, t0: torch\u001b[38;5;241m.\u001b[39mTensor, t1: torch\u001b[38;5;241m.\u001b[39mTensor, dt: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m     26\u001b[0m                        integrator_kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor], \u001b[38;5;241m*\u001b[39madditional_dynamic_args):\n\u001b[0;32m     27\u001b[0m     integrator_spec \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     28\u001b[0m         __integrator_type\u001b[38;5;241m.\u001b[39mintegrator_tableau\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mto(x0\u001b[38;5;241m.\u001b[39mdevice, x0\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[0;32m     29\u001b[0m         __integrator_type\u001b[38;5;241m.\u001b[39mis_adaptive,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m         __integrator_type\u001b[38;5;241m.\u001b[39muse_local_extrapolation\n\u001b[0;32m     33\u001b[0m         )\n\u001b[1;32m---> 35\u001b[0m     c_state, c_time, intermediate_states, intermediate_times, error_in_state \u001b[38;5;241m=\u001b[39m \u001b[43mroutines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_ivp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrator_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrator_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_dynamic_args\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c_state, c_time, intermediate_states, intermediate_times, error_in_state\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\integrators\\routines.py:82\u001b[0m, in \u001b[0;36msolve_ivp\u001b[1;34m(forward_fn, integrator_specification, x0, t0, t1, dt, integrator_kwargs, additional_dynamic_args)\u001b[0m\n\u001b[0;32m     78\u001b[0m trial_restarts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39mwhere(t1 \u001b[38;5;241m>\u001b[39m t0, (c_time \u001b[38;5;241m+\u001b[39m dt) \u001b[38;5;241m<\u001b[39m t1, (c_time \u001b[38;5;241m+\u001b[39m dt) \u001b[38;5;241m>\u001b[39m t1)):\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# print(f\"{t0.item():<12.8e}/{c_time.item():>12.8e}/{t1.item():>12.8e}/{dt:>12.8e}\", end='\\r')\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     delta_state_lower, delta_state_upper, delta_time \u001b[38;5;241m=\u001b[39m \u001b[43mhelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtruncated_bits_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtruncated_bits_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtableau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# If local extrapolation is enabled, we take the higher order estimate, otherwise the lower order one\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     delta_state \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     92\u001b[0m         delta_state_upper \u001b[38;5;28;01mif\u001b[39;00m use_local_extrapolation \u001b[38;5;28;01melse\u001b[39;00m delta_state_lower\n\u001b[0;32m     93\u001b[0m     )\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\integrators\\helpers.py:85\u001b[0m, in \u001b[0;36mcompute_step\u001b[1;34m(fn, state, time, step, tableau, additional_dynamic_args, intermediate_stages, is_adaptive)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stage_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(intermediate_stages\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     80\u001b[0m     c_coeff, a_coeff \u001b[38;5;241m=\u001b[39m tableau[stage_index][\u001b[38;5;241m0\u001b[39m], tableau[stage_index][\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     81\u001b[0m     intermediate_stages[stage_index] \u001b[38;5;241m=\u001b[39m fn(\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;66;03m# We use `compensated_sum` instead of `sum` to avoid truncation at each stage calculation\u001b[39;00m\n\u001b[0;32m     83\u001b[0m         state\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;241m+\u001b[39m step\n\u001b[1;32m---> 85\u001b[0m         \u001b[38;5;241m*\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompensated_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mintermediate_stages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_coeff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     86\u001b[0m         time \u001b[38;5;241m+\u001b[39m c_coeff \u001b[38;5;241m*\u001b[39m step,\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;241m*\u001b[39madditional_dynamic_args,\n\u001b[0;32m     88\u001b[0m         )\n\u001b[0;32m     89\u001b[0m lower_order_estimate \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m*\u001b[39m util\u001b[38;5;241m.\u001b[39mcompensated_sum(\n\u001b[0;32m     90\u001b[0m     k \u001b[38;5;241m*\u001b[39m b \u001b[38;5;28;01mfor\u001b[39;00m k, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(intermediate_stages, tableau[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m     91\u001b[0m     )\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# To have a valid value, we set `higher_order_estimate` to the same value as `lower_order_estimate`\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Further down, this will simplify the code as we won't have to account for invalid values\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\util.py:65\u001b[0m, in \u001b[0;36mcompensated_sum\u001b[1;34m(iterable_to_sum)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m partial_sum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         partial_sum, truncated_bits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(v), torch\u001b[38;5;241m.\u001b[39mzeros_like(v)\n\u001b[1;32m---> 65\u001b[0m     partial_sum, truncated_bits \u001b[38;5;241m=\u001b[39m \u001b[43mpartial_compensated_sum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_sum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncated_bits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m partial_sum \u001b[38;5;241m+\u001b[39m truncated_bits\n",
      "File \u001b[1;32m~\\PycharmProjects\\ReCoDE-NeuralODEs\\neuralode\\util.py:41\u001b[0m, in \u001b[0;36mpartial_compensated_sum\u001b[1;34m(next_value, partial_sum_truncated_bits)\u001b[0m\n\u001b[0;32m     33\u001b[0m     partial_sum, truncated_bits \u001b[38;5;241m=\u001b[39m partial_sum_truncated_bits\n\u001b[0;32m     34\u001b[0m temporary_partial_sum \u001b[38;5;241m=\u001b[39m partial_sum \u001b[38;5;241m+\u001b[39m next_value\n\u001b[0;32m     35\u001b[0m truncated_bits \u001b[38;5;241m=\u001b[39m truncated_bits \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m     36\u001b[0m     torch\u001b[38;5;241m.\u001b[39mabs(partial_sum) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(next_value),\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# When the magnitude of the partial sum is larger, truncation occurs for v and vice versa when v is larger\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     (partial_sum \u001b[38;5;241m-\u001b[39m temporary_partial_sum) \u001b[38;5;241m+\u001b[39m next_value,\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# First the negation of the truncated value of v is computed from the partial sum and\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# the temporary partial sum, and then adding it to v gives the truncated bits\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m     (\u001b[43mnext_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemporary_partial_sum\u001b[49m)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;241m+\u001b[39m partial_sum,  \u001b[38;5;66;03m# As before, but the role of v and partial_sum are swapped\u001b[39;00m\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     44\u001b[0m partial_sum \u001b[38;5;241m=\u001b[39m temporary_partial_sum\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m partial_sum, truncated_bits\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\neuralode-DDywRCkr-py3.12\\Lib\\site-packages\\torch\\utils\\_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cart_pole_net.load_state_dict(best_params)\n",
    "cart_pole_net.eval()\n",
    "\n",
    "final_state, _, sha_states, sha_times, _ = current_integrator.apply(nn_controlled_pendulum, state_dataset[0], initial_time, final_time, initial_timestep, {'atol': atol, 'rtol': rtol}, mass_cart, mass_pole, length_pole, gravity, friction_cart, friction_pole)\n",
    "\n",
    "cart_pole_net(sha_states, sha_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351ae64a15716c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:56:15.600346Z",
     "start_time": "2024-07-03T13:56:15.188252Z"
    }
   },
   "outputs": [],
   "source": [
    "cart_x = sha_states[...,2]\n",
    "cart_y = torch.zeros_like(cart_x)\n",
    "\n",
    "pendulum_x = torch.sin(sha_states[...,0]) * length_pole + cart_x\n",
    "pendulum_y = torch.cos(sha_states[...,0]) * length_pole\n",
    "plot_pendulum(pendulum_x, pendulum_y, cart_x, cart_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef44c15cce9ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:56:23.340515Z",
     "start_time": "2024-07-03T13:56:15.601353Z"
    }
   },
   "outputs": [],
   "source": [
    "HTML(animate_pendulum(pendulum_x, pendulum_y, cart_x, cart_y, sha_times, frame_time=1000/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f015ca3ca34ef75b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T01:02:09.451078Z",
     "start_time": "2024-07-02T01:02:09.449215Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
